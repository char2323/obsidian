## Shell

Shell 编程是一种在 Unix/Linux 系统中通过编写脚本（一系列命令的集合）来自动化任务的强大工具，它的用途非常广泛，尤其在系统管理、数据处理和自动化流程中发挥着重要作用。以下是 Shell 编程的主要用途和优势：

---

### **1. 自动化重复任务**
   - **日常操作**：自动执行备份、日志清理、文件整理等重复性工作。
     ```bash
     # 每天凌晨自动备份目录
     0 0 * * * tar -czf /backup/data_$(date +%F).tar.gz /path/to/data
     ```
   - **批量处理**：一键重命名文件、批量转换格式、处理文本等。
     ```bash
     # 批量将.txt文件改为.md
     for file in *.txt; do mv "$file" "${file%.txt}.md"; done
     ```

---

### **2. 系统管理和监控**
   - **服务器维护**：检查磁盘空间、监控进程、定时重启服务等。
     ```bash
     # 检查磁盘使用率超过90%的分区
     df -h | awk '$5 > 90% {print $6}'
     ```
   - **报警脚本**：当服务器异常时（如 CPU 过高），自动发送邮件通知。
     ```bash
     if [ $(uptime | awk '{print $NF}') > 5 ]; then echo "High CPU!" | mail -s "Alert" admin@example.com; fi
     ```

---

### **3. 数据处理和日志分析**
   - **提取信息**：从日志文件中过滤错误信息或统计访问量。
     ```bash
     # 统计Nginx日志中404错误的次数
     grep " 404 " /var/log/nginx/access.log | wc -l
     ```
   - **文本处理**：结合 `grep`、`awk`、`sed` 快速处理 CSV 或日志文件。
     ```bash
     # 提取文件第二列并排序
     awk '{print $2}' data.txt | sort -u
     ```

---

### **4. 快速原型开发**
   - **验证想法**：在开发大型程序前，用 Shell 快速验证逻辑或流程。
   - **组合工具**：调用 Python、Perl 等脚本，或结合命令行工具（如 `curl`）实现功能。
     ```bash
     # 调用Python处理数据并保存结果
     python process_data.py | grep "Result" > output.txt
     ```

---

### **5. 软件部署和 DevOps**
   - **自动化部署**：通过脚本安装依赖、配置环境、拉取代码。
     ```bash
     # 示例：部署Web应用
     git pull origin master
     npm install
     systemctl restart apache2
     ```
   - **CI/CD 流程**：与 Jenkins、GitHub Actions 等工具结合，触发自动化测试和发布。

---

### **6. 跨平台和轻量化**
   - **兼容性**：Shell 脚本能在大多数 Linux/Unix 系统和 macOS 上运行（Windows 需 WSL 或 Cygwin）。
   - **资源占用少**：无需额外依赖，适合嵌入式设备或资源受限的环境。

---

### **7. 提高效率和可重复性**
   - **避免手动输入**：复杂命令通过脚本保存，减少错误。
   - **知识沉淀**：脚本即文档，记录操作流程供团队复用。

---

### **简单示例：自动备份并压缩日志**
```bash
#!/bin/bash
# 备份Nginx日志
backup_dir="/var/log/backups"
mkdir -p "$backup_dir"
tar -czf "$backup_dir/nginx_$(date +%Y%m%d).tar.gz" /var/log/nginx/*.log
find "$backup_dir" -type f -mtime +30 -delete  # 删除30天前的备份
```

---

### **学习建议**
- **入门工具**：先掌握 `bash` 基础语法，再学习 `grep`、`awk`、`sed` 等工具。
- **适用场景**：适合自动化、文本处理和系统任务，但复杂计算或 GUI 程序建议用 Python/其他语言。

Shell 编程的核心价值在于**用简单的脚本替代繁琐的手工操作**，是程序员和运维人员的必备技能。

## grep、awk、sed

`grep`、`awk` 和 `sed` 是 Linux/Unix 系统中三个强大的文本处理工具，常被组合使用以实现高效的文本搜索、提取、替换和格式化操作。它们被称为“文本处理三剑客”，在 Shell 脚本和命令行中应用广泛。以下是它们的详细介绍和典型用法：

---

### **1. `grep`：文本搜索工具**
**用途**：在文件或输入流中快速搜索匹配特定模式（正则表达式）的行。  
**核心功能**：过滤、查找关键字。  
**常用选项**：
- `-i`：忽略大小写
- `-v`：反向匹配（显示不包含模式的行）
- `-n`：显示行号
- `-r`：递归搜索目录
- `-E`：支持扩展正则表达式（等同于 `egrep`）

### **示例**
```bash
# 查找文件中包含 "error" 的行
grep "error" /var/log/syslog

# 忽略大小写搜索 "warning"
grep -i "warning" log.txt

# 递归搜索目录下所有 .py 文件中的 "import"
grep -r "import" /path/to/code/ --include="*.py"

# 使用正则表达式匹配 IP 地址
grep -Eo '[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}' access.log
```

---

### **2. `awk`：文本分析和格式化工具**
**用途**：按列处理结构化文本（如 CSV、日志），支持计算、统计和格式化输出。  
**核心功能**：字段提取、数据统计、条件过滤。  
**基本语法**：  
```bash
awk 'pattern {action}' file
```
- `pattern`：匹配条件（如 `/error/` 或 `$1 > 100`）
- `action`：对匹配行执行的操作（如 `print $2}`）
- 内置变量：`$0`（整行）、`$1`（第一列）、`NF`（列数）、`NR`（行号）

### **示例**
```bash
# 打印文件的第1列和第3列
awk '{print $1, $3}' data.txt

# 过滤第2列大于100的行
awk '$2 > 100 {print $0}' data.txt

# 统计日志中每个IP的访问次数
awk '{ip_count[$1]++} END {for (ip in ip_count) print ip, ip_count[ip]}' access.log

# 计算文件的行数、列数和总和
awk '{sum+=$1} END {print "Lines:", NR, "Columns:", NF, "Sum:", sum}' data.txt
```

---

### **3. `sed`：流编辑器（文本替换工具）**
**用途**：对文本进行流式编辑（替换、删除、插入等），支持正则表达式。  
**核心功能**：批量替换、删除行、插入内容。  
**常用选项**：
- `-i`：直接修改文件（原地编辑）
- `-e`：指定多个编辑命令
- `s/old/new/`：替换操作（默认只替换每行第一个匹配）
- `s/old/new/g`：全局替换

### **示例**
```bash
# 替换文件中的 "old" 为 "new"（仅输出到终端）
sed 's/old/new/' file.txt

# 全局替换并保存到文件
sed -i 's/old/new/g' file.txt

# 删除包含 "debug" 的行
sed '/debug/d' file.txt

# 在第3行后插入一行文本
sed '3a This is a new line' file.txt

# 同时执行多个操作（替换+删除）
sed -e 's/foo/bar/g' -e '/baz/d' file.txt
```

---

### **三者的对比与组合使用**
| 工具   | 主要用途                     | 优势                              | 典型场景                     |
|--------|----------------------------|-----------------------------------|----------------------------|
| `grep` | 搜索过滤文本                | 速度快，适合简单匹配              | 查找日志错误、过滤命令输出   |
| `awk`  | 按列处理结构化数据          | 支持计算、统计和复杂逻辑          | 分析日志、数据报表生成      |
| `sed`  | 文本替换和编辑              | 适合批量修改文件内容              | 配置文件更新、文本批量替换   |

### **组合使用示例**
```bash
# 1. 提取nginx日志中404错误的IP，并统计出现次数
grep " 404 " access.log | awk '{print $1}' | sort | uniq -c

# 2. 替换文件中的日期格式（YYYY-MM-DD → DD/MM/YYYY）
sed 's/\([0-9]\{4\}\)-\([0-9]\{2\}\)-\([0-9]\{2\}\)/\3\/\2\/\1/g' dates.txt

# 3. 计算CSV文件中第2列的总和
awk -F ',' '{sum+=$2} END {print sum}' data.csv
```

---

### **学习建议**
1. **先掌握基础正则表达式**（如 `.*`, `^`, `$`, `[0-9]`），这是三者的通用技能。
2. **从简单用例开始**：
   - `grep` 先用于搜索，
   - `awk` 处理列数据，
   - `sed` 做批量替换。
3. **组合使用**：通过管道（`|`）将三者结合，发挥最大威力。

这些工具是 Linux 系统管理和数据分析的基石，熟练掌握后可以大幅提升工作效率！

## 正则

正则表达式（Regular Expression，简称 **Regex**）是一种用于匹配、查找和操作文本的强大工具，广泛应用于 `grep`、`sed`、`awk`、编程语言（如 Python/JavaScript）等场景。以下是正则表达式的基础语法和实用技巧，帮助你快速上手。

---

### **1. 基础匹配规则**
#### **1.1 普通字符**
- 大多数字符（字母、数字）直接匹配自身。
  ```bash
  "hello" 匹配 "hello world" 中的 "hello"
  ```

#### **1.2 特殊字符（需转义）**
- 这些字符在正则中有特殊含义，如需匹配它们本身，需用 `\` 转义：
  ```bash
  . * + ? [ ] { } ( ) ^ $ | \
  ```
  **示例**：
  ```bash
  "1\+1=2"  匹配 "1+1=2"（`+` 是特殊字符，需转义）
  ```

---

### **2. 常用元字符**
| 元字符 | 说明                          | 示例                     |
|--------|-----------------------------|--------------------------|
| `.`    | 匹配任意**单个字符**（除换行符） | `a.c` 匹配 "abc", "a 1 c"  |
| `^`    | 匹配行首                      | `^hello` 匹配以 "hello" 开头的行 |
| `$`    | 匹配行尾                      | `world$` 匹配以 "world" 结尾的行 |
| `\d`   | 匹配数字（等价于 `[0-9]`）      | `\d\d` 匹配 "12", "45"   |
| `\w`   | 匹配单词字符（字母、数字、下划线） | `\w+` 匹配 "abc_123"     |
| `\s`   | 匹配空白字符（空格、制表符等）    | `hello\sworld` 匹配 "hello world" |

---

### **3. 字符类（匹配一组字符）**
| 语法            | 说明                     | 示例                     |
|-----------------|------------------------|--------------------------|
| `[abc]`         | 匹配 a、b 或 c           | `[aeiou]` 匹配元音字母    |
| `[a-z]`         | 匹配任意小写字母          | `[a-z]\+` 匹配 "abc+"    |
| `[^abc]`        | 匹配**非** a、b、c 的字符 | `[^0-9]` 匹配非数字字符  |

**示例**：
```bash
# 匹配所有大写字母或数字
grep '[A-Z0-9]' file.txt
```

---

### **4. 量词（控制重复次数）**
| 量词    | 说明                     | 示例                     |
|---------|------------------------|--------------------------|
| `*`     | 匹配前一个字符 **0 次或多次** | `a*b` 匹配 "b", "aab"    |
| `+`     | 匹配前一个字符 **1 次或多次** | `a+b` 匹配 "ab", "aaab"  |
| `?`     | 匹配前一个字符 **0 次或 1 次**  | `a?b` 匹配 "b", "ab"     |
| `{n}`   | 匹配前一个字符 **恰好 n 次** | `a{3}` 匹配 "aaa"        |
| `{n,}`  | 匹配前一个字符 **至少 n 次** | `a{2,}` 匹配 "aa", "aaa" |
| `{n,m}` | 匹配前一个字符 **n 到 m 次** | `a{2,4}` 匹配 "aa", "aaa" |

**示例**：
```bash
# 匹配连续3个数字
grep '[0-9]\{3\}' file.txt
# 或（使用扩展正则，-E）
grep -E '[0-9]{3}' file.txt
```

---

### **5. 分组和捕获**
| 语法          | 说明                     | 示例                     |
|--------------|------------------------|--------------------------|
| `(pattern)`  | 分组并捕获匹配的文本       | `(ab)+` 匹配 "ab", "abab" |
| `\n`         | 引用第 n 个分组的内容      | 见下方替换示例            |

**示例**（在 `sed` 中反向引用）：
```bash
# 将 "2023-01-01" 替换为 "01/01/2023"
sed 's/\([0-9]\{4\}\)-\([0-9]\{2\}\)-\([0-9]\{2\}\)/\2\/\3\/\1/' dates.txt
```

---

### **6. 逻辑与分支**
| 语法      | 说明               | 示例                     |
|----------|------------------|--------------------------|
| ` | `      | 或逻辑（匹配任意一个） | `cat |dog ` 匹配 "cat" 或 "dog" |
| `(?=)`   | 正向预查（匹配后面是某模式的位置） | `Windows(?=10)` 匹配 "Windows 10" 中的 "Windows" |

---

### **7. 实用示例**
#### **7.1 匹配邮箱地址**
```bash
grep -E '\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,6}\b' emails.txt
```

#### **7.2 匹配 IP 地址**
```bash
grep -Eo '([0-9]{1,3}\.){3}[0-9]{1,3}' access.log
```

#### **7.3 提取 HTML 标签中的内容**
```bash
sed -E 's/<[^>]*>//g' file.html  # 删除所有HTML标签
```

---

### **8. 工具中的正则差异**
- **`grep`**：默认支持基础正则（BRE），`-E` 启用扩展正则（ERE）。
- **`sed`**：默认用 BRE，`-E`（或 `-r`）启用 ERE。
- **`awk`**：直接支持 ERE，无需额外选项。

---

### **9. 练习建议**
1. 用 `grep` 练习搜索日志文件中的错误：
   ```bash
   grep -E 'error|fail' /var/log/syslog
   ```
2. 用 `sed` 批量替换文件中的日期格式。
3. 用 `awk` 提取 CSV 文件的特定列并统计。

掌握这些基础后，你可以逐步学习更复杂的正则表达式（如非贪婪匹配、零宽断言等）！